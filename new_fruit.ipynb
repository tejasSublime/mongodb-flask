{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model with knn and svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_store_models():\n",
    "    # Load the data\n",
    "    data = pd.read_json('data.json')\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data[['r1', 'r2', 'r3', 'r4', 'r5', 'r6']])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = normalized_data\n",
    "    y = data['category']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the SVM model\n",
    "    with open('./svm_model.pkl', 'wb') as f:\n",
    "        pickle.dump(svm_model, f)\n",
    "\n",
    "    # Train the KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the KNN model\n",
    "    with open('./knn_model.pkl', 'wb') as f:\n",
    "        pickle.dump(knn_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_new_data(new_data):\n",
    "    # Load the SVM model\n",
    "    with open('svm_model.pkl', 'rb') as f:\n",
    "        svm_model = pickle.load(f)\n",
    "\n",
    "    # Load the KNN model\n",
    "    with open('knn_model.pkl', 'rb') as f:\n",
    "        knn_model = pickle.load(f)\n",
    "\n",
    "    # Normalize the new data\n",
    "    scaler = MinMaxScaler()\n",
    "    # normalized_new_data = scaler.transform([list(new_data.values())])\n",
    "    normalized_new_data = scaler.transform([list(new_data.values())])\n",
    "\n",
    "    # Classify the new data using the SVM model\n",
    "    svm_prediction = svm_model.predict(normalized_new_data)\n",
    "    print(\"SVM classification:\", svm_prediction)\n",
    "\n",
    "    # Classify the new data using the KNN model\n",
    "    knn_prediction = knn_model.predict(normalized_new_data)\n",
    "    print(\"KNN classification:\", knn_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_store_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hp\\Documents\\work\\mongodb-flask\\new_fruit.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_data \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mr1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m25\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m55\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mr6\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m320\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m classify_new_data(new_data)\n",
      "\u001b[1;32mc:\\Users\\Hp\\Documents\\work\\mongodb-flask\\new_fruit.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# normalized_new_data = scaler.transform([list(new_data.values())])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m normalized_new_data \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform([\u001b[39mlist\u001b[39;49m(new_data\u001b[39m.\u001b[39;49mvalues())])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Classify the new data using the SVM model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Hp/Documents/work/mongodb-flask/new_fruit.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m svm_prediction \u001b[39m=\u001b[39m svm_model\u001b[39m.\u001b[39mpredict(normalized_new_data)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\Documents\\work\\mongodb-flask\\env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\Documents\\work\\mongodb-flask\\env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:512\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    500\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \n\u001b[0;32m    502\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m        Transformed data.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    514\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    515\u001b[0m         X,\n\u001b[0;32m    516\u001b[0m         copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    522\u001b[0m     X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n",
      "File \u001b[1;32mc:\\Users\\Hp\\Documents\\work\\mongodb-flask\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "new_data = {\n",
    "    'r1': 25,\n",
    "    'r2': 55,\n",
    "    'r3': 90,\n",
    "    'r4': 160,\n",
    "    'r5': 250,\n",
    "    'r6': 320\n",
    "}\n",
    "\n",
    "\n",
    "classify_new_data(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
